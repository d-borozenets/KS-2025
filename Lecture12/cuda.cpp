#include <iostream>
using namespace std;

// =====================================================
// 1. GPU-кернел
//    __global__ означає, що функція виконується на GPU,
//    але викликається з CPU.
// =====================================================
__global__
void vector_add(const float* a, const float* b, float* c, int n)
{
    // Обчислюємо global index потоку
    // Кожен потік виконує цю функцію для одного елемента.
    int idx = blockIdx.x * blockDim.x + threadIdx.x;

    // Перевірка, щоб не вилізти за межі масиву
    if (idx < n)
        c[idx] = a[idx] + b[idx];
}

int main()
{
    const int N = 10;
    const int bytes = N * sizeof(float);

    // =====================================================
    // 2. Виділяємо пам’ять на CPU (host)
    // =====================================================
    float h_a[N], h_b[N], h_c[N];

    // Ініціалізуємо початкові дані
    for (int i = 0; i < N; i++)
    {
        h_a[i] = i;
        h_b[i] = 100 + i;
    }

    // =====================================================
    // 3. Виділяємо пам’ять на GPU (device)
    // =====================================================
    float *d_a, *d_b, *d_c;
    cudaMalloc(&d_a, bytes);   // виділити пам’ять на GPU
    cudaMalloc(&d_b, bytes);
    cudaMalloc(&d_c, bytes);

    // =====================================================
    // 4. Копіюємо дані з CPU → GPU
    // =====================================================
    cudaMemcpy(d_a, h_a, bytes, cudaMemcpyHostToDevice);
    cudaMemcpy(d_b, h_b, bytes, cudaMemcpyHostToDevice);

    // =====================================================
    // 5. Запуск кернела
    //
    // <<< blocks, threads_per_block >>>
    //
    // Наприклад: 1 блок по 256 потоків.
    // Для маленьких прикладів цього достатньо.
    // =====================================================
    int threads = 256;
    int blocks  = (N + threads - 1) / threads;

    vector_add<<<blocks, threads>>>(d_a, d_b, d_c, N);

    // Чекаємо завершення GPU
    cudaDeviceSynchronize();

    // =====================================================
    // 6. Копіюємо результат назад: GPU → CPU
    // =====================================================
    cudaMemcpy(h_c, d_c, bytes, cudaMemcpyDeviceToHost);

    // =====================================================
    // 7. Виводимо результат
    // =====================================================
    cout << "Result: ";
    for (int i = 0; i < N; i++)
        cout << h_c[i] << " ";
    cout << endl;

    // =====================================================
    // 8. Звільняємо пам’ять на GPU
    // =====================================================
    cudaFree(d_a);
    cudaFree(d_b);
    cudaFree(d_c);

    return 0;
}
